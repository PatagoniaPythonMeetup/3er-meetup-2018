{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Diferentes clasificadores en la decodificación del conjunto de datos Haxby\n",
    "=====================================================\n",
    "\n",
    "Comparación de diferentes clasificadores en una tarea de decodificación de reconocimiento de objetos visuales.\n",
    "\n",
    "https://github.com/nilearn/nilearn/tree/master/examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Cargar los datos y aplicarle transformaciones simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtener datos usando la captura de conjunto de datos nilearn\n",
    "from nilearn import datasets\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "\n",
    "# imprimir información básica sobre el conjunto de datos\n",
    "print('First subject anatomical nifti image (3D) located is at: %s' %\n",
    "      haxby_dataset.anat[0])\n",
    "print('First subject functional nifti image (4D) is located at: %s' %\n",
    "      haxby_dataset.func[0])\n",
    "\n",
    "# cargar etiquetas \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "labels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "stimuli = labels['labels']\n",
    "# identificar las etiquetas de estado en reposo para poder descartarlas\n",
    "task_mask = (stimuli != 'rest')\n",
    "\n",
    "# encontrar nombres de las etiquetas activas restantes\n",
    "categories = stimuli[task_mask].unique()\n",
    "\n",
    "# extraer etiquetas que indiquen a qué adquisición (estimulación) pertenece\n",
    "session_labels = labels['chunks'][task_mask]\n",
    "\n",
    " # Cargar los datos de fMRI\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "# Para la decodificación, la estandarización a menudo es muy importante\n",
    "mask_filename = haxby_dataset.mask_vt[0]\n",
    "masker = NiftiMasker(mask_img=mask_filename, standardize=True)\n",
    "func_filename = haxby_dataset.func[0]\n",
    "masked_timecourses = masker.fit_transform(func_filename)[task_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Definir los diferentes clasificadores a usar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clasificador de vectores de soporte\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(C=1., kernel=\"linear\")\n",
    "\n",
    "# Regresión logistica\n",
    "from sklearn.linear_model import (LogisticRegression,\n",
    "                                  RidgeClassifier,\n",
    "                                  RidgeClassifierCV,\n",
    "                                  )\n",
    "logistic = LogisticRegression(C=1., penalty=\"l1\")\n",
    "logistic_50 = LogisticRegression(C=50., penalty=\"l1\")\n",
    "logistic_l2 = LogisticRegression(C=1., penalty=\"l2\")\n",
    "\n",
    "# Validación cruzada de clasificadores\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_cv = GridSearchCV(SVC(C=1., kernel=\"linear\"),\n",
    "                      param_grid={'C': [.1, .5, 1., 5., 10., 50., 100.]},\n",
    "                      scoring='f1', n_jobs=1)\n",
    "\n",
    "logistic_cv = GridSearchCV(LogisticRegression(C=1., penalty=\"l1\"),\n",
    "                           param_grid={'C': [.1, .5, 1., 5., 10., 50., 100.]},\n",
    "                           scoring='f1')\n",
    "logistic_l2_cv = GridSearchCV(LogisticRegression(C=1., penalty=\"l2\"),\n",
    "                              param_grid={\n",
    "                                  'C': [.1, .5, 1., 5., 10., 50., 100.]\n",
    "                              },\n",
    "                              scoring='f1')\n",
    "\n",
    "\n",
    "# El clasificador de cresta tiene un objeto 'CV' que puede establecer sus\n",
    "# parámetros más rápidos que usar un GridSearchCV\n",
    "ridge = RidgeClassifier()\n",
    "ridge_cv = RidgeClassifierCV()\n",
    "\n",
    "# Diccionario que contiene todos nuestros clasificadores\n",
    "classifiers = {'SVC': svm,\n",
    "               'SVC cv': svm_cv,\n",
    "               'log l1': logistic,\n",
    "               'log l1 50': logistic_50,\n",
    "               'log l1 cv': logistic_cv,\n",
    "               'log l2': logistic_l2,\n",
    "               'log l2 cv': logistic_l2_cv,\n",
    "               'ridge': ridge,\n",
    "               'ridge cv': ridge_cv\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Calcular puntajes de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Objeto de división de datos para la validación cruzada\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_score\n",
    "cv = LeaveOneGroupOut()\n",
    "\n",
    "import time\n",
    "\n",
    "classifiers_scores = {}\n",
    "\n",
    "for classifier_name, classifier in sorted(classifiers.items()):\n",
    "    classifiers_scores[classifier_name] = {}\n",
    "    print(70 * '_')\n",
    "\n",
    "    for category in categories:\n",
    "        classification_target = stimuli[task_mask].isin([category])\n",
    "        t0 = time.time()\n",
    "        classifiers_scores[classifier_name][category] = cross_val_score(\n",
    "            classifier,\n",
    "            masked_timecourses,\n",
    "            classification_target,\n",
    "            cv=cv,\n",
    "            groups=session_labels,\n",
    "            scoring=\"f1\",\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"%10s: %14s -- scores: %1.2f +- %1.2f, time %.2fs\" %\n",
    "            (\n",
    "                classifier_name,\n",
    "                category,\n",
    "                classifiers_scores[classifier_name][category].mean(),\n",
    "                classifiers_scores[classifier_name][category].std(),\n",
    "                time.time() - t0,\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Graficar diagrama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "\n",
    "tick_position = np.arange(len(categories))\n",
    "plt.xticks(tick_position, categories, rotation=45)\n",
    "\n",
    "for color, classifier_name in zip(\n",
    "        ['b', 'c', 'm', 'g', 'y', 'k', '.5', 'r', '#ffaaaa'],\n",
    "        sorted(classifiers)):\n",
    "    score_means = [classifiers_scores[classifier_name][category].mean()\n",
    "                   for category in categories]\n",
    "    plt.bar(tick_position, score_means, label=classifier_name,\n",
    "            width=.11, color=color)\n",
    "    tick_position = tick_position + .09\n",
    "\n",
    "plt.ylabel('Classification accurancy (f1 score)')\n",
    "plt.xlabel('Visual stimuli category')\n",
    "plt.ylim(ymin=0)\n",
    "plt.legend(loc='lower center', ncol=3)\n",
    "plt.title(\n",
    "    'Category-specific classification accuracy for different classifiers')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)  Trazar el mapa de 'face' frente a 'house' para los diferentes clasificadores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Usa promedio fondo\n",
    "from nilearn import image\n",
    "mean_epi_img = image.mean_img(func_filename)\n",
    "\n",
    "# Restringir la decodificación para enfrentar 'face' frente 'house'\n",
    "condition_mask = stimuli.isin(['face', 'house'])\n",
    "masked_timecourses = masked_timecourses[\n",
    "    condition_mask[task_mask]]\n",
    "stimuli = (stimuli[condition_mask] == 'face')\n",
    "# Transformar los estímulos en valores binarios\n",
    "stimuli.astype(np.int)\n",
    "\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "for classifier_name, classifier in sorted(classifiers.items()):\n",
    "    classifier.fit(masked_timecourses, stimuli)\n",
    "\n",
    "    if hasattr(classifier, 'coef_'):\n",
    "        weights = classifier.coef_[0]\n",
    "    elif hasattr(classifier, 'best_estimator_'):\n",
    "        weights = classifier.best_estimator_.coef_[0]\n",
    "    else:\n",
    "        continue\n",
    "    weight_img = masker.inverse_transform(weights)\n",
    "    weight_map = weight_img.get_data()\n",
    "    threshold = np.max(np.abs(weight_map)) * 1e-3\n",
    "    plot_stat_map(weight_img, bg_img=mean_epi_img,\n",
    "                  display_mode='z', cut_coords=[-15],\n",
    "                  threshold=threshold,\n",
    "                  title='%s: face vs house' % classifier_name)\n",
    "\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
