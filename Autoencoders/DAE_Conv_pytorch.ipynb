{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform as trf\n",
    "from utiles import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_loader(\"data/lfwcrop_grey\",shape=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratio = .1\n",
    "data = target + n_ratio*np.random.normal(0, 1, target.shape)\n",
    "data = np.clip(data, a_max=1, a_min=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split( data, target, test_size=.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_r, x_test_dl = to_tensor( x_test, b_size=50 )\n",
    "y_test_r, y_test_dl = to_tensor( y_test, b_size=50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_faces(x_train, y_train, 2, h_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, img_shape=(28, 28)):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.out_s = np.array(img_shape)/8\n",
    "        self.c1 = nn.Conv2d( 1, 10, 3, padding=1, stride=1 )\n",
    "        self.c2 = nn.Conv2d( 10, 20, 3, padding=1, stride=1 )\n",
    "        self.c3 = nn.Conv2d( 20, 40, 3, padding=1, stride=1 )\n",
    "\n",
    "        self.ct1 = nn.ConvTranspose2d( 40, 20, 3, padding=1, stride=2 )\n",
    "        self.ct2 = nn.ConvTranspose2d( 20, 10, 3, padding=1, stride=2 )\n",
    "        self.ct3 = nn.ConvTranspose2d( 10, 1, 3, padding=1, stride=2 )\n",
    "        self.convf = nn.Conv2d( 1, 1, 3, padding=1, stride=1 )\n",
    "\n",
    "    def encode( self, x ):\n",
    "        x = nn.ReLU(True)( self.c1( x ) )\n",
    "        x = nn.MaxPool2d( kernel_size=2, stride=2 )( x )\n",
    "        x = nn.ReLU(True)( self.c2( x ) )\n",
    "        x = nn.MaxPool2d( kernel_size=2, stride=2 )( x )\n",
    "        x = nn.ReLU(True)( self.c3( x ) )\n",
    "        x = nn.MaxPool2d( kernel_size=2, stride=2 )( x )\n",
    "        return x\n",
    "\n",
    "    def decode( self, code ):\n",
    "#         out_s = np.array(code.size())[-2:]*2 \n",
    "        out_s = self.out_s *2\n",
    "        x = self.ct1( code, output_size=out_s )\n",
    "        x = nn.ReLU( True )( x )\n",
    "        out_s = out_s*2\n",
    "        x = self.ct2( x, output_size=out_s )\n",
    "        x = nn.ReLU( True )( x )\n",
    "        out_s = out_s*2\n",
    "        x = self.ct3( x, output_size=out_s )\n",
    "        x = self.convf( x )\n",
    "        x = nn.Tanh()( x )\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        code = self.encode( x )\n",
    "        rec = self.decode( code )\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(img_shape=(64, 64))\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw, x_train_dl = to_tensor( x_train, b_size=50 )\n",
    "y_train_raw, y_train_dl = to_tensor( y_train, b_size=50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam( model.parameters(), lr=0.003 )\n",
    "n_epochs = 5\n",
    "for e in range( n_epochs ):\n",
    "    for d, t in zip(x_train_dl, y_train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        img = d[0]\n",
    "        img = Variable(img)\n",
    "\n",
    "        trg = t[0]\n",
    "        trg = Variable(trg)\n",
    "\n",
    "        output = model( img )\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"epoch [{}/{}], loss:{:.4f}\".format(e + 1, n_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"pesos/pytorch_dae_conv.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict( torch.load(\"pesos/pytorch_dae_conv.h5\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data = next( iter(x_test_dl) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model( Variable(d_data[0])).data.numpy()\n",
    "\n",
    "ddata = x_test[:50]\n",
    "ttarget = y_test[:50]\n",
    "predicted = predicted.reshape( predicted.shape[0], 64, 64 )\n",
    "ddata.shape, ttarget.shape, predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_faces(ddata, ttarget, 5, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import median\n",
    "from skimage.morphology import selem\n",
    "s = selem.square(3)\n",
    "i = np.random.randint( 50 )\n",
    "img = median( x_test[i], s )\n",
    "f = plt.figure()\n",
    "ax = f.add_subplot(1,2,1)\n",
    "ax.imshow(x_test[i], cmap=plt.cm.gray)\n",
    "ax = f.add_subplot(1,2,2)\n",
    "ax.imshow(img, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
